## 1.分布式系统

### 1.1 为什么要进行系统拆分

为什么要进行系统拆分？如何进行系统拆分？拆分后不用 Dubbo 可以吗？

### 1.2 分布式服务框架（RPC框架Dubbo）

- 说一下 Dubbo 的工作原理？注册中心挂了可以继续通信吗？
- Dubbo 支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？
- Dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？
- Dubbo 的 spi 思想是什么？
- 如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？
- 分布式服务接口的幂等性如何设计（比如不能重复扣款）？
- 分布式服务接口请求的顺序性如何保证？
- 如何自己设计一个类似 Dubbo 的 RPC 框架？
- CAP 定理的 P 是什么？

### 1.3 分布式锁

- Zookeeper 都有哪些应用场景？
- 使用 Redis 如何设计分布式锁？使用 Zookeeper 来设计分布式锁可以吗？以上两种分布式锁的实现方式哪种效率比较高？

### 1.4 分布式事务

分布式事务了解吗？你们如何解决分布式事务问题的？TCC 如果出现网络连不通怎么办？XA 的一致性如何保证？

### 1.5 分布式会话

集群部署时的分布式 Session 如何实现？

### 1.6 流式处理框架（实时计算Flink）

## 2. 高并发架构

### 2.1 如何设计一个高并发系统

### 2.2 消息队列

#### 消息队列使用场景及优缺点

优点：消息队列的三个核心使用场景：解耦、异步、削峰

- 解耦：一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦，但是其实这个调用是不需要直接同步调用接口的，这里就可以考虑使用MQ进行系统解耦。通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，上游系统就跟其它下游系统彻底解耦了
- 异步：
- 削峰：典型的使用场景就是秒杀业务用于流量削峰场景

缺点：系统可用性降低，系统复杂度提高，一致性问题

#### 消息队列的高可用

##### RabbitMQ的高可用性

RabbitMQ**基于主从**（非分布式）实现高可用性。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

1. 单机模式：Demo级别

2. 普通集群模式（无高可用性）（只同步queue元数据，不同步消息数据）

   - 普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。
   - **创建的 queue，只会放在一个 RabbitMQ 实例上**，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。
   - 消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。
   
   缺点：
   
   - **MQ内部可能产生大量的数据传输。没做到所谓的分布式**，就是个普通集群。因为这种模式导致要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。
   - 可用性无保障，queue所在节点宕机，数据就丢了。如果开启了消息持久化，**让 RabbitMQ 落地存储消息的话**，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。

​		普通集群模式**主要是提高吞吐量的**，就是说让集群中多个节点来服务某个 queue 的读写操作。

3. 镜像集群模式（高可用性）（既同步queue元数据，也同步消息数据）

   - 在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据
   - 每次写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。

   缺点：
   
   - 性能开销太大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重
   - 不是分布式的，**没有扩展性可言**，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并**没有办法线性扩展**

##### Kafka的高可用性

Kafka最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**。

Partition分区数和Broker数关系：

1. 如果**Partition数等于Broker数**， Kafka集群将比较均衡
2. 如果**Partition数小于Broker数**，某个Broker节点上不存在当前topic的分区，Broker节点可能被闲置，最终导致Kafka集群吞吐率下降
3. 如果**Partition数大于Broker数**，抛异常：java.lang.IllegalArgumentException: Invalid partition given with record: 1 is not in the range [0...0]，建议将Partition数必须设置为Broker数的整数倍

HA机制：副本机制

1. Kafka 0.8 以后，提供了 HA 机制，就是 **replica（复制品） 副本机制**。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。
2. 所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。
3. 写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader原因如下：**要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题**，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。

副本机制是如何实现高可用的：

1. 如果某个 broker 宕机了，那个 broker上面的 partition 在其他机器上都有副本。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。
2. **写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）
3. **消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

##### ==RocketMQ的高可用性==



#### 消息不被重复消费（消息消费的幂等性）

Kafka重复消费场景：

1. Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，**每隔一段时间**（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。
2. 但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。

需要结合业务来看，主要有如下思路：

- 比如拿个数据要写库，先根据主键查一下，如果这数据都有了，就别插入了，update 一下。
- 比如是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如不是上面两个场景，那做的稍微复杂一点，需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后消费者这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

#### 消息的可靠性传输（如何处理消息丢失的问题）



#### 消息的顺序性



#### 消息队列延时及过期失效问题



#### 如何设计一个消息队列



### 2.3 搜索引擎（ElasticSearch）

### 2.4 缓存

#### 线程模型

套接字，I/O多路复用，文件事件处理器

#### 五个对象及底层数据结构

Redis 都有哪些数据类型？分别在哪些场景下使用比较合适？

简单动态字符串（SDS）

- 常数时间复杂度获取字符串长度
- 杜绝缓冲区溢出：先扩展再拼接
- 减少修改时的内存分配次数
- 二进制安全
- 兼容部分C字符串函数

字符串



列表



哈希对象



集合对象



有序集合对象

- ziplist、skiplist


#### 过期删除机制，淘汰机制

Redis 的过期策略都有哪些？手写一下 LRU 代码实现？

#### 持久化

Redis 的持久化有哪几种方式？

不同的持久化机制都有什么优缺点？

持久化机制具体底层是如何实现的？

RDB（BGSAVE）、AOF（命令先写到缓冲区再写AOF文件）

#### 主从复制

如何保证 Redis 高并发、高可用？

Redis 的主从复制原理能介绍一下么？

#### 哨兵

Redis 的哨兵原理能介绍一下么？

#### 集群

16384个槽

Redis 集群模式的工作原理能说一下么？

在集群模式下，Redis 的 key 是如何寻址的？

分布式寻址都有哪些算法？

#### 一致性哈希

了解一致性 hash 算法吗？

如何动态增加和删除一个节点？

#### 事务

Redis 的并发竞争问题是什么？如何解决这个问题？

了解 Redis 事务的 CAS 方案吗？

#### 缓存并发竞争

解释：多个客户端写一个 key，如果顺序错了，数据就不对了。但是顺序我们无法控制。

解决方案：使用分布式锁，例如 zk，同时加入数据的时间戳。同一时刻，只有抢到锁的客户端才能写入，同时，写入时，比较当前数据的时间戳和缓存中数据的时间戳。

#### 缓存雪崩

- 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。
- 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。
- 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

#### 缓存穿透

每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 `set -999 UNKNOWN` 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。

#### 缓存击穿

- 若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。
- 若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。
- 若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前**主动地重新构建缓存或者延后缓存的过期时间**，以保证所有的请求能一直访问到对应的缓存。

#### 数据库和缓存双写一致性

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，**先更新数据库，然后再删除缓存**。

### 2.5 分库分表

- 为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？
- 现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？
- 如何设计可以动态扩容缩容的分库分表方案？
- 分库分表之后，id 主键如何处理？

### 2.6 读写分离

- 如何实现 MySQL 的读写分离？MySQL 主从复制原理是啥？如何解决 MySQL 主从同步的延时问题？

## 3. 高可用架构

### 3.1 如何设计一个高可用系统

### 3.2 限流

### 3.3 熔断

### 3.4 降级

