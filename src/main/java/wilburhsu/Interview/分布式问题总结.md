## 1.分布式系统

### 1.1 为什么要进行系统拆分

为什么要进行系统拆分？如何进行系统拆分？拆分后不用 Dubbo 可以吗？

### 1.2 分布式服务框架（RPC框架Dubbo）

- 说一下 Dubbo 的工作原理？注册中心挂了可以继续通信吗？
- Dubbo 支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？
- Dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？
- Dubbo 的 spi 思想是什么？
- 如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？
- 分布式服务接口的幂等性如何设计（比如不能重复扣款）？
- 分布式服务接口请求的顺序性如何保证？
- 如何自己设计一个类似 Dubbo 的 RPC 框架？
- CAP 定理的 P 是什么？

### 1.3 分布式锁

- Zookeeper 都有哪些应用场景？
- 使用 Redis 如何设计分布式锁？使用 Zookeeper 来设计分布式锁可以吗？以上两种分布式锁的实现方式哪种效率比较高？

### 1.4 分布式事务

分布式事务了解吗？你们如何解决分布式事务问题的？TCC 如果出现网络连不通怎么办？XA 的一致性如何保证？

### 1.5 分布式会话

集群部署时的分布式 Session 如何实现？

### 1.6 流式处理框架（实时计算Flink）

## 2. 高并发架构

### 2.1 如何设计一个高并发系统

### 2.2 消息队列

#### 消息队列使用场景及优缺点

优点：消息队列的三个核心使用场景：解耦、异步、削峰

- 解耦：一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦，但是其实这个调用是不需要直接同步调用接口的，这里就可以考虑使用MQ进行系统解耦。通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，上游系统就跟其它下游系统彻底解耦了
- 异步：
- 削峰：典型的使用场景就是秒杀业务用于流量削峰场景

缺点：系统可用性降低，系统复杂度提高，一致性问题

#### 消息队列的推拉模式

在rocketmq里，consumer被分为2类：MQPullConsumer和MQPushConsumer，其实本质都是拉模式（pull），即consumer轮询从broker拉取消息。
区别是：
push方式里，consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。

pull方式里，取消息的过程需要用户自己写，首先通过打算消费的Topic拿到MessageQueue的集合，遍历MessageQueue集合，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue。

#### 消息队列的高可用

##### RabbitMQ的高可用性

RabbitMQ**基于主从**（非分布式）实现高可用性。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

1. 单机模式：Demo级别

2. 普通集群模式（无高可用性）（只同步queue元数据，不同步消息数据）

   - 普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。
   - **创建的 queue，只会放在一个 RabbitMQ 实例上**，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。
   - 消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。
   
   缺点：
   
   - **MQ内部可能产生大量的数据传输。没做到所谓的分布式**，就是个普通集群。因为这种模式导致要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。
   - 可用性无保障，queue所在节点宕机，数据就丢了。如果开启了消息持久化，**让 RabbitMQ 落地存储消息的话**，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。

​		普通集群模式**主要是提高吞吐量的**，就是说让集群中多个节点来服务某个 queue 的读写操作。

3. 镜像集群模式（高可用性）（既同步queue元数据，也同步消息数据）

   - 在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据
   - 每次写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。

   缺点：
   
   - 性能开销太大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重
   - 不是分布式的，**没有扩展性可言**，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并**没有办法线性扩展**

##### Kafka的高可用性

Kafka最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**。

Partition分区数和Broker数关系：

1. 如果**Partition数等于Broker数**， Kafka集群将比较均衡
2. 如果**Partition数小于Broker数**，某个Broker节点上不存在当前topic的分区，Broker节点可能被闲置，最终导致Kafka集群吞吐率下降
3. 如果**Partition数大于Broker数**，抛异常：java.lang.IllegalArgumentException: Invalid partition given with record: 1 is not in the range [0...0]，建议将Partition数必须设置为Broker数的整数倍

HA机制：副本机制

1. Kafka 0.8 以后，提供了 HA 机制，就是 **replica（复制品） 副本机制**。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。
2. 所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。
3. 写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader原因如下：**要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题**，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。

副本机制是如何实现高可用的：

1. 如果某个 broker 宕机了，那个 broker上面的 partition 在其他机器上都有副本。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。
2. **写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）
3. **消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

##### ==RocketMQ的高可用性==



#### 消息不被重复消费（消息消费的幂等性）

Kafka重复消费场景：

1. Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，**每隔一段时间**（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。
2. 但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset，尴尬了。重启之后，少数消息会再次消费一次。

需要结合业务来看，主要有如下思路：

- 比如拿个数据要写库，先根据主键查一下，如果这数据都有了，就别插入了，update 一下。
- 比如是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如不是上面两个场景，那做的稍微复杂一点，需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后消费者这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

#### 消息的可靠性传输（如何处理消息丢失的问题）

##### RabbitMQ的可靠性处理

1. 生产者丢数据

   **开启RabbitMQ事务**（同步，消耗性能，吞吐量下降大，不推荐）

   - 生产者**发送数据之前**开启 RabbitMQ 事务 `channel.txSelect` ，然后发送消息；

   - 如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务 `channel.txRollback` ，然后重试发送消息；

   - 如果收到了消息，那么可以提交事务 `channel.txCommit` 。

   **开启confirm模式**（异步，推荐）

   - 在生产者端设置开启 `confirm` 模式之后，每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会回传一个 `ack` 消息，告知你这个消息 ok 了。

   - 如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。

   - 你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

2. RabbitMQ丢数据

   **开启 RabbitMQ 的持久化**，消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据**，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，**可能导致少量数据丢失**，但是这个概率较小。

   设置持久化有**两个步骤**：

   - 创建 queue 的时候将其设置为持久化

   这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。

   - 消息设置为持久化

   发送消息的时候将消息的 `deliveryMode` 设置为 2，此时 RabbitMQ 就会将消息持久化到磁盘上去。

   **必须要同时设置这两个持久化才行**，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。

   极端情况：哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。

   所以，**持久化可以跟生产者那边的 `confirm` 机制配合起来**，只有**消息被持久化到磁盘之后，才会通知生产者 `ack`** 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack` ，你也是可以自己重发的。

3. 消费者丢数据（**关闭RabbitMQ自动ack**）

   消费者如果丢失了数据，主要是因为你消费的时候，**刚消费到，还没处理，结果进程挂了**，比如重启了，RabbitMQ 认为你都消费了，这数据就丢了。
   
   这个时候得用 RabbitMQ 提供的 `ack` 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 `ack` ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。这样的话，如果你还没处理完，就没有 `ack` 了。那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

##### Kafka的可靠性处理

1. 消费者丢失数据

   消费者唯一丢数据的情况：消费者消费到消息后，消费者那边**自动提交了 offset**，Kafka 认为消费者已经消费好了这个消息，但其实消费者才刚准备处理这个消息，还没处理，自己就挂了，此时这条消息就丢失了。

   解决方法： Kafka 会自动提交 offset，那么只要**关闭自动提交** offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是**可能会有重复消费**，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。

2. Kafka丢失数据

   Kakfa丢失数据场景：Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。如果此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，还没有同步的数据就丢失了。

   解决方法：一般是要求起码设置如下 4 个参数：

   - 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求**每个 partition 必须有至少 2 个副本**。
   - 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求**一个 leader 至少感知到有一个 follower 还跟自己保持联系**，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
   - 在 producer 端设置 `acks=all` ：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
   - 在 producer 端设置 `retries=MAX` （很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。

3. 生产者会不会丢失数据？

   如果按照上述的思路设置了 `acks=all` ，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

##### ==RocketMQ的可靠性处理==



#### 消息的顺序性

消息顺序错乱的场景：

1. RabbitMQ

   一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。数据就出现了明显的错乱。

2. Kafka

   比如说我们建了一个 topic，有三个 partition。

   生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。

   消费者从 partition 中取出来数据的时候，也一定是有顺序的。

   到这里，顺序还是 ok 的，没有错乱。

   接着，我们在消费者里可能会搞**多个线程来并发处理消息**。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。

解决方案：

1. RabbitMQ

   - 拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；

   - 就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

2. Kafka

   - 一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
   - 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

#### 消息队列延时、过期失效、积压问题

如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？

具体场景的解决办法：

1. 大量消息在MQ 里积压了几个小时了还没解决

   临时紧急扩容，具体操作步骤和思路如下：

   - 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
   - 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
   - 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
   - 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
   - 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。

2.  MQ中的消息过期失效了

   消息队列设置过期时间之后，如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了，导致大量的数据直接丢失

   解决方法：

   **批量重导**。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。

3.  MQ都快写满了

   临时写程序，接入数据来消费，**消费一个丢弃一个，都不要了**，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据。

#### 如何设计一个消息队列

参照开源技术从如下几个角度进行考虑：

- 首先这个 mq 得**支持可伸缩性**，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？
- 其次你得考虑一下这个 mq 的**数据要不要落地磁盘**吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。
- 其次你考虑一下你的 mq 的**可用性**啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。
- 能不能支持**数据 0 丢失**啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。

### 2.3 搜索引擎（ElasticSearch）

### 2.4 缓存

#### 线程模型

Redis 内部使用文件事件处理器 `file event handler` ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序（编译时自动选择系统中性能最高的I/O多路复用函数库）
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。

客户端与 Redis 的一次通信过程：

![image](https://note.youdao.com/yws/public/resource/aba0f08fcb448be8bda00fbd1ddd049d/xmlnote/FDA1084D00C34C1392074E780D4D76FD/9776)

首先，Redis 服务端进程初始化的时候，会将 server socket 的 `AE_READABLE` 事件与连接应答处理器关联。

客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给**连接应答处理器**。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。

假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 socket01 会产生 `AE_READABLE` 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 `AE_READABLE` 事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与命令回复处理器关联。

如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 `ok` ，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。

#### 为什么 Redis 单线程模型也能效率这么高？

- 纯内存操作。
- 核心是基于非阻塞的 IO 多路复用机制。
- C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。
- 单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。

**注意！** Redis 6.0 之后的版本抛弃了单线程模型这一设计，**原本使用单线程运行的 Redis 也开始选择性地使用多线程模型**。

前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。

**Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。** 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。

#### 五个对象及底层数据结构

底层数据结构

| 对象所使用的底层数据结构 | OBJECT ENCODING 命令输出 |
| :--- | :--- |
| 整数 | int |
| embstr编码的简单动态字符串（SDS） | embstr |
| 简单动态字符串 | raw |
| 字典 | hashtable |
| 双端链表 | linkedlist |
| 压缩列表 | ziplist |
| 整数集合 | intset |
| 跳跃表和字典 | skiplist |

简单动态字符串（SDS）

- 常数时间复杂度获取字符串长度
- 杜绝缓冲区溢出：先扩展再拼接
- 减少修改时的内存分配次数
- 二进制安全
- 兼容部分C字符串函数

五种对象的底层实现

| 类型                  | 编码                | 备注                                                         |
| --------------------- | ------------------- | ------------------------------------------------------------ |
| 字符串（String）      | int，raw，embstr    | 普通的 set 和 get，做简单的 KV 缓存                          |
| 有序列表（List）      | ziplist，linkedlist | 通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类<br />通过 lrange 命令，读取某个闭区间内的元素<br />实现简单的消息队列 |
| 哈希对象（Hash）      | ziplist，hashtable  | 可存储结构化的数据，比如一个对象（无对象嵌套）               |
| 集合对象（ Set）      | intset，hashtable   | 无序集合，自动去重<br />基于 set 可以实现交集、并集、差集的操作 |
| 有序集合对象（ ZSet） | ziplist，skiplist   | 排序的 set，去重但可以排序                                   |


#### 过期删除机制，淘汰机制

Redis 的过期策略都有哪些？手写一下 LRU 代码实现？

#### 持久化

Redis 的持久化有哪几种方式？

不同的持久化机制都有什么优缺点？

持久化机制具体底层是如何实现的？

RDB（BGSAVE）、AOF（命令先写到缓冲区再写AOF文件）

#### 主从复制

如何保证 Redis 高并发、高可用？

Redis 的主从复制原理能介绍一下么？

#### 哨兵

Redis 的哨兵原理能介绍一下么？

#### 集群

16384个槽

Redis 集群模式的工作原理能说一下么？

在集群模式下，Redis 的 key 是如何寻址的？

分布式寻址都有哪些算法？

#### 一致性哈希

了解一致性 hash 算法吗？

如何动态增加和删除一个节点？

#### 事务

Redis 的并发竞争问题是什么？如何解决这个问题？

了解 Redis 事务的 CAS 方案吗？

#### 缓存并发竞争

解释：多个客户端写一个 key，如果顺序错了，数据就不对了。但是顺序我们无法控制。

解决方案：使用分布式锁，例如 zk，同时加入数据的时间戳。同一时刻，只有抢到锁的客户端才能写入，同时，写入时，比较当前数据的时间戳和缓存中数据的时间戳。

#### 缓存雪崩

- 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。
- 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。
- 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

#### 缓存穿透

每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 `set -999 UNKNOWN` 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。

#### 缓存击穿

- 若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。
- 若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。
- 若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前**主动地重新构建缓存或者延后缓存的过期时间**，以保证所有的请求能一直访问到对应的缓存。

#### 数据库和缓存双写一致性

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，**先更新数据库，然后再删除缓存**。

### 2.5 分库分表

- 为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？
- 现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？
- 如何设计可以动态扩容缩容的分库分表方案？
- 分库分表之后，id 主键如何处理？

### 2.6 读写分离

- 如何实现 MySQL 的读写分离？MySQL 主从复制原理是啥？如何解决 MySQL 主从同步的延时问题？

## 3. 高可用架构

### 3.1 如何设计一个高可用系统

### 3.2 限流

### 3.3 熔断

### 3.4 降级

